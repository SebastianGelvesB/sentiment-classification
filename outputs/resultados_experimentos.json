[
    {
        "modelo": "bert-base-uncased",
        "hiperparametros": {
            "model_name": "bert-base-uncased",
            "lr": 3e-05,
            "weight_decay": 0.0001,
            "batch_size": 4,
            "epochs": 3,
            "save_path": "../models/bert_sentiment_analysis_model"
        },
        "accuracy": 0.8533,
        "f1_macro": 0.8575,
        "reporte_clasificacion": {
            "Extremely Negative": {
                "precision": 0.8496124031007752,
                "recall": 0.9256756756756757,
                "f1-score": 0.8860145513338723,
                "support": 592.0
            },
            "Negative": {
                "precision": 0.8656565656565657,
                "recall": 0.8232468780019212,
                "f1-score": 0.843919251600197,
                "support": 1041.0
            },
            "Neutral": {
                "precision": 0.8382126348228043,
                "recall": 0.8788368336025848,
                "f1-score": 0.8580441640378549,
                "support": 619.0
            },
            "Positive": {
                "precision": 0.8425110132158591,
                "recall": 0.8078141499472017,
                "f1-score": 0.8247978436657682,
                "support": 947.0
            },
            "Extremely Positive": {
                "precision": 0.8696369636963697,
                "recall": 0.8797996661101837,
                "f1-score": 0.8746887966804979,
                "support": 599.0
            },
            "accuracy": 0.8533438651922064,
            "macro avg": {
                "precision": 0.853125916098475,
                "recall": 0.8630746406675135,
                "f1-score": 0.8574929214636381,
                "support": 3798.0
            },
            "weighted avg": {
                "precision": 0.8535395258580841,
                "recall": 0.8533438651922064,
                "f1-score": 0.8528678357051054,
                "support": 3798.0
            }
        }
    }
]